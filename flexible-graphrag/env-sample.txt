# Flexible GraphRAG Configuration

# Data Source (filesystem, cmis, alfresco)
DATA_SOURCE=filesystem
SOURCE_PATHS=["./sample-docs/cmispress.txt"]

# Sample Text for Testing (optional - overrides default Dune text)
# SAMPLE_TEXT="Luke Skywalker is a Jedi Knight from Tatooine. His father is Darth Vader, formerly known as Anakin Skywalker."

# Source Path Examples:
# Windows single file: SOURCE_PATHS=["C:\Documents\report.pdf"]
# Windows multiple files: SOURCE_PATHS=["C:\file1.pdf", "D:\folder\file2.docx"] 
# Windows whole directory: SOURCE_PATHS=["C:\Documents\reports"]  # Note: processes ALL files
# macOS single file: SOURCE_PATHS=["/Users/username/Documents/report.pdf"]
# Linux single file: SOURCE_PATHS=["/home/username/documents/report.pdf"]
# See docs/SOURCE-PATH-EXAMPLES.md for more detailed examples
# Note: UI clients use different env vars (PROCESS_FOLDER_PATH, VITE_PROCESS_FOLDER_PATH)

# ====================================================================
# 1. GRAPH DATABASE CONFIGURATION
# ====================================================================

GRAPH_DB=neo4j
#GRAPH_DB=kuzu
#GRAPH_DB=none

# Enable knowledge graph extraction 
#ENABLE_KNOWLEDGE_GRAPH=false
ENABLE_KNOWLEDGE_GRAPH=true

# Graph Database Connection Configurations:
# Neo4j
GRAPH_DB_CONFIG={"url": "bolt://localhost:7687", "username": "neo4j", "password": "password"}

# Kuzu  
#GRAPH_DB_CONFIG={"db_path": "./kuzu_db"}

# ====================================================================
# SCHEMA CONFIGURATION - Controls entity and relationship extraction
# ====================================================================

# Schema set to default uses SAMPLE_SCHEMA in config.py
# "entities": Literal["PERSON", "ORGANIZATION", "LOCATION", "TECHNOLOGY", "PROJECT", "DOCUMENT"],
# "relations": Literal["WORKS_FOR", "LOCATED_IN", "USES", "COLLABORATES_WITH", "DEVELOPS", "MENTIONS"],
SCHEMA_NAME=default
#SCHEMA_NAME=none

# Custom schema example (more examples in docs/SCHEMA-EXAMPLES.md):
# SCHEMAS=[{"name": "business", "schema": {"entities": ["COMPANY", "PERSON"], "relations": ["WORKS_FOR"]}}]

# ====================================================================
# 2. VECTOR DATABASE CONFIGURATION  
# ====================================================================

VECTOR_DB=neo4j
#VECTOR_DB=qdrant
#VECTOR_DB=elasticsearch
#VECTOR_DB=opensearch
#VECTOR_DB=none

# Vector Database Connection Configurations:
# Qdrant
#VECTOR_DB_CONFIG={"host": "localhost", "port": 6333, "collection_name": "hybrid_search_vector", "https": false}

# Elasticsearch
#VECTOR_DB_CONFIG={"url": "http://localhost:9200", "index_name": "hybrid_search_vector"}

# OpenSearch Configuration (Vector Store) - Dense vector search
#VECTOR_DB_CONFIG={"url": "http://localhost:9201", "index_name": "hybrid_search_vector"}

# Neo4j VECTOR database configuration (separate from graph)
VECTOR_DB_CONFIG={"url": "bolt://localhost:7687", "username": "neo4j", "password": "password", "index_name": "hybrid_search_vector", "database": "neo4j"}


# ====================================================================
# 3. SEARCH DATABASE CONFIGURATION
# ====================================================================

#SEARCH_DB=bm25
SEARCH_DB=elasticsearch
#SEARCH_DB=opensearch
#SEARCH_DB=none

# Search Database Connection Configurations:
# Elasticsearch
SEARCH_DB_CONFIG={"url": "http://localhost:9200", "index_name": "hybrid_search_fulltext"}

# OpenSearch Configuration (Search Store) - BM25 fulltext search
#SEARCH_DB_CONFIG={"url": "http://localhost:9201", "index_name": "hybrid_search_fulltext"}

# ====================================================================
# 4. LLM CONFIGURATION
# ====================================================================

LLM_PROVIDER=openai
USE_OPENAI=true
#LLM_PROVIDER=ollama
#USE_OPENAI=false

# OpenAI Configuration (if using OpenAI)
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini
EMBEDDING_MODEL=text-embedding-3-small  # 1536 dimensions, recommended
# OPENAI_TIMEOUT=120.0  # LLM request timeout in seconds (default: 2 minutes)

# Ollama Configuration (if using Ollama)
#OLLAMA_MODEL=llama3.1:8b
#OLLAMA_MODEL=llama3.2:latest
#OLLAMA_MODEL=gpt-oss:20b
#EMBEDDING_MODEL=mxbai-embed-large
#OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_TIMEOUT=300.0  # LLM request timeout in seconds (default: 5 minutes - higher for local processing)

# Azure OpenAI Configuration (if using Azure)
# AZURE_OPENAI_TIMEOUT=120.0  # LLM request timeout in seconds

# Anthropic Configuration (if using Claude)
# ANTHROPIC_TIMEOUT=120.0  # LLM request timeout in seconds

# Gemini Configuration (if using Google)
# GEMINI_TIMEOUT=120.0  # LLM request timeout in seconds

# ====================================================================
# 5. CONTENT SOURCES CONFIGURATION
# ====================================================================

# CMIS Configuration (if using CMIS)
CMIS_URL=http://localhost:8080/alfresco/api/-default-/public/cmis/versions/1.1/atom
CMIS_USERNAME=admin
CMIS_PASSWORD=admin

# Alfresco Configuration (if using Alfresco)
ALFRESCO_URL=http://localhost:8080/alfresco
ALFRESCO_USERNAME=admin
ALFRESCO_PASSWORD=admin

# ====================================================================
# DATABASE CONNECTION DETAILS (Individual Configs)
# ====================================================================

# Neo4j Configuration (for both vector and graph storage)
# Browser URL: http://localhost:7474/browser (for database management and queries)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password
# NEO4J_DATABASE=neo4j  # Optional: specify database name (default: neo4j)

# Neo4j AuraDB (cloud) example:
# NEO4J_URI=neo4j+s://<dbid>.databases.neo4j.io
# NEO4J_USER=neo4j
# NEO4J_PASSWORD=<aura-generated-password>
# Console URL: https://console.neo4j.io

# Elasticsearch Configuration
ELASTICSEARCH_URL=http://localhost:9200
ELASTICSEARCH_USERNAME=
ELASTICSEARCH_PASSWORD=

# Qdrant Configuration
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_API_KEY=
# QDRANT_COLLECTION=hybrid_search  # Optional: collection name
# QDRANT_HTTPS=false  # Use HTTPS for remote Qdrant instances

# OpenSearch Configuration
OPENSEARCH_URL=http://localhost:9201
OPENSEARCH_USERNAME=
OPENSEARCH_PASSWORD=

# Processing Configuration
CHUNK_SIZE=1024
CHUNK_OVERLAP=128
MAX_TRIPLETS_PER_CHUNK=10

# Timeout configurations moved to docs/TIMEOUT-CONFIGURATIONS.md
# Uncomment and adjust these if you need custom timeout values:
# DOCLING_TIMEOUT=300
# KG_EXTRACTION_TIMEOUT=3600  
# OPENAI_TIMEOUT=120.0  # For OpenAI LLM requests
# OLLAMA_TIMEOUT=300.0  # For Ollama LLM requests